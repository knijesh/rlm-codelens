# =============================================================================
# RLM-Codelens Configuration
# =============================================================================

# RLM Architecture Analyzer Configuration (for --deep analysis)
# Backend: "openai" or "anthropic"
RLM_BACKEND=openai
# Model for RLM architecture analysis
RLM_MODEL=gpt-4o
# RLM execution environment: "local" or "docker"
RLM_ENVIRONMENT=local
# Max iterations per RLM completion call
RLM_MAX_ITERATIONS=30

# OpenAI API Key (only needed if using openai backend with --deep)
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Anthropic API Key (only needed if using anthropic backend with --deep)
# ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Repository Scan Configuration
# Comma-separated list of additional directories to exclude from scan
# SCAN_EXCLUDE_PATTERNS=migrations,generated

# Budget Configuration
BUDGET_LIMIT=50.0
BUDGET_ALERT_THRESHOLD=80

# Logging
LOG_LEVEL=INFO
LOG_FILE=outputs/analysis.log
