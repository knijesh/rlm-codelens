# GitHub API Configuration
# Get your token from: https://github.com/settings/tokens
# Required scopes: repo (for public repos), or repo+read:org (for private)
GITHUB_TOKEN=ghp_xxxxxxxxxxxxxxxxxxxx

# OpenAI API Configuration
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Database Configuration
# Using PostgreSQL for storing embeddings and analysis results
DATABASE_URL=postgresql://localhost/pytorch_analysis
# Alternative with credentials:
# DATABASE_URL=postgresql://username:password@localhost:5432/pytorch_analysis

# Budget Configuration
# Maximum spending limit for API calls (in USD)
BUDGET_LIMIT=50.0
# Alert threshold (percentage of budget)
BUDGET_ALERT_THRESHOLD=80

# RLM Configuration
# Model for root RLM calls (orchestration)
RLM_ROOT_MODEL=gpt-3.5-turbo
# Model for sub-LLM calls (cheaper)
RLM_SUB_MODEL=gpt-3.5-turbo
# Maximum recursion depth
RLM_MAX_DEPTH=3

# Analysis Configuration
# Repository to analyze
REPO_OWNER=pytorch
REPO_NAME=pytorch
# Optional: limit to recent data only
# DAYS_LIMIT=365

# Embedding Configuration
# OpenAI embedding model
EMBEDDING_MODEL=text-embedding-3-small
# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=1000

# Clustering Configuration
# Minimum cluster size for HDBSCAN
MIN_CLUSTER_SIZE=50
# Minimum samples for HDBSCAN
MIN_SAMPLES=10

# Visualization Configuration
# Maximum nodes to display in graph
MAX_GRAPH_NODES=1000
# Minimum correlation strength (0-1)
MIN_CORRELATION_STRENGTH=0.5

# Development/Testing
# Set to True to use sample data instead of full repo
USE_SAMPLE_DATA=False
SAMPLE_SIZE=1000

# Logging
LOG_LEVEL=INFO
LOG_FILE=outputs/analysis.log
